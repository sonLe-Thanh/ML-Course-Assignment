     The development sector &#8212; including government, the third sector, and,       since 1999, the UK's       Department for International Development (DFID) &#8212; has followed a strategy       of building support for       development, monitoring success through annual surveys of public opinion.
With expenditure cuts       and a ring-fenced aid budget, public attitudes to development have become       salient in policy terms.
The research addressed these issues and has had a demonstrable and       material impact upon       thinking, policy and practice through three channels:            It has reshaped DFID's approach to surveying public attitudes towards         development as well         as the OECD's proposed global poll;       It has reshaped the debate across the sector through the Finding           Frames Report;       It has shaped the #IF Campaign's work on Monitoring, Evaluation, and         Learning.
1.
DFID and OECD surveys on public support for development     In January 2009 the UK House of Commons International Development       Committee (IDC), noting       that public support is essential to an effective development policy,       launched an inquiry into Aid         Under Pressure, to which the UCL researchers submitted evidence.
The       evidence, based on the       underlying research above, argued that DFID did not know as much as it       could or should about the       nature of public support for development in the UK [1].
The submitted       evidence was later written up       in [a] and [b].
That evidence suggested that the survey data was based on       a question badly       adapted to gauging levels of support.
In particular it tapped concern in       general rather than a more       valid indicator such as support for government spending on development       assistance in relation to       other parts of the budget such as the NHS, police, jobseeker's allowance.
DFID also failed to       explore or control for relevant individual covariates of support &#8212; such as       political attitudes,       knowledge, or newspaper readership &#8212; which would allow for a more       fine-grained approach to `the       public'.
On the basis of the written evidence we were invited to give oral       evidence to the IDC, which       we did in March 2009 [2].
The evidence formed the backbone of Chapter 4 of the Committee's final       report [3].
(See, in       particular, notes 220, 221, 225 and 228 and pp.
62-3.)
It challenged       existing practice, with the       Report noting that "The Secretary of State told us that the question of       the methodology used in       DFID's surveys was not one that the Department had considered."
[3, pp.
44-45].
One of the       Report's recommendations was:     "If DFID is to build public support for development effectively it needs       first to establish what       people's attitudes are.
This requires the collection of information that       truly reflects public       opinion.
We do not believe that DFID's surveys, as they are currently       designed, achieve       this.
They focus on whether people are concerned about poverty, rather       than whether they       would support increased funding for development, nor do they attempt to       assess the relative       importance people place on development compared to domestic policy areas       such as health       and education.
We recommend that DFID examines how it assesses the level       of public       support for development and redesigns its surveys to address the       weaknesses we have       identified."
[3, p. 45]     The recommendation was taken up by DFID and alterations were made to the       national survey of       public attitudes towards development from 2009 onwards.
An explanation of       the new measures of       support was provided near the beginning of the 2009 Survey Report, which       directly cites the IDC       recommendation that came from our research:     "The IDC Aid Under Pressure report in June 2009 suggested that the DFID       attitudinal       survey, as previously conducted, did not effectively establish people's       support for       development aid.
In particular, it questioned the usefulness of the       measure of `concern'       towards poverty in developing countries and argued that it might be more       helpful to ask       what priority should be given to increased spending on development       assistance compared       to other policy areas, such as the NHS or law and order, so as to       establish its relative       importance.
In response to this, the most recent wave included two new       questions to       establish these priorities.
Respondents were asked to consider a number of       global or       international issues (16 in total) where taxpayers' money is spent and to       select their top five       most important for the Government to spend money on.
In addition, they       were asked to       prioritise support for poor countries relative to five domestic issues,       ranking those issues in       order of priority, a question previously asked in the segmentation study."
[4, p. 3]     More recently, the OECD &#8212; which is the main bilateral aid forum &#8212; has       started work on a cross-national       survey into public support for development.
A `roadmap' has been       commissioned for this       Global Solidarity Opinion Poll [5].
The report cites our research, noting       that: "the most important       issue to be settled for any public opinion poll: to ensure what it is that       we want to measure and       then to look at how to do that.
The former starts with acknowledging that       support, opinion, attitude,       knowledge, awareness (which are often used interchangeably) are in reality       different concepts."
2.
The Finding Frames Report and best practice         in the UK development sector     The highly influential Finding Frames report was published in       2010 by Oxfam and the umbrella       organisation for British Overseas NGOs for Development (BOND) [6].
The       report argues that the       way in which `development' is presented to the pubic matters and has       definitively shifted the       debate in the UK development sector &#8212; helping cement the idea that a       deeper, more complex       conversation is necessary [7].
The report draws on a rich psychological       literature on values and       behaviour to develop an argument for `reframing' how development is       presented to the public, for       example to move away from notions of charity or aid towards justice and       dialogue.
The report       notes the distinct lack of evidence about the values that drive public       engagement with       development, before identifying the underpinning research as the exception       and going on to outline       the arguments of van Heerde and Hudson 2010 [a] and Hudson and vanHeerde       Hudson [b] [6].
The Report, influenced by the research, which is explicitly referenced at       pp.
16, 20, 48-9, and 59,       has shifted the debate in the sector as well as what is considered best       practice.
Best practice: The Finding Frames report has directly         shaped the design of current large-         scale campaigning initiatives.
For example, in May 2011, Oxfam launched         a new 4-year         global campaign across all 17 of its country organisations called GROW         [8].
The campaign         was explicitly designed using the Finding Frames report [8].
Other key initiatives, such as         the Global Poverty Project's 1 Billion Reasons, the Gates         Foundation, and the 2013 #IF         Campaign (see below), use the Finding Frames report to design         their public engagement         work.
Debate: The most recent report on UK public attitudes, jointly         published by Institute for         Public Policy Research and the Overseas Development Institute [9], picks         up on our         arguments about moral vs. self-interested framing, citing both our         published papers.
They         conclude that attempts by DFID "to reframe the case for development as         being in Britain's         self-interest do not resonate as much as approaches that focus on what         is `right' or fair."
[9,         p. 23].
The report has helped shift the public and media debate, with         this specific finding         being reported in The Guardian and the New Statesman.
The #IF Campaign     In anticipation of the June 2013 G8 meeting in the UK, over 100       organisations came together in a       coalition to launch the #IF Campaign in January 2013.
The campaign had       four main demands: aid       increases, stopping land grabs and tax dodging, and increased financial       transparency.
It aimed to       change the quality of public engagement with development to secure policy       change.
The campaign has a number of key performance indicators, many of which       pertained to public       support; the monitoring and evaluation was done through a national poll in       three waves with a       sample size of 1,500 from January to June 2013.
This was the largest such       poll in the sector's       history, and the survey design was explicitly based on Hudson and Hudson's       research [10] &#8212; with       their suggested measures of support, additional questions on knowledge,       political attitudes all       being used.
In early January both researchers were invited to sit on the       campaign's Monitoring,       Evaluation, and Learning Working Group to help with the design and       analysis of further public       engagement data collection and analysis.
Thanks to the research, the       campaign had `a realistic       understanding of public support for each stage' enabling it to refine its       strategies for `maximum       advocacy impact with the government' [10].
