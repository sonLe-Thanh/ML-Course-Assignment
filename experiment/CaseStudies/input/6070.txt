     Research at Leicester has made an important contribution to assessment       policy and practice in the       UK and beyond.
Researchers have worked with the largest examination boards       and teacher       trainers, such as [text removed for publication], to develop new       assessment products, create new       assessment tools, use new quality assurance procedures, and improve       assessment training.
In the field of skills and performance analysis, Fulcher has acted as       co-chair of the [text removed for       publication] project since 2010, to design the next generation of language       tests for [text removed for       publication].
Research into speaking assessment (A, B, D, E)       impacts on the current design       process.
The research will effect university admissions testing for the       next 20 years.
Fulcher has       also been an advisor to [text removed for publication] (2011 - 2013) on       their new university       admissions English tests.
Leicester research on scoring procedures has had significant impact upon       the practices of [text       removed for publication].
Norton has worked with [text removed for       publication] test data to       investigate the impact on individual test performance of other speakers.
Her research informs       rating practice in speaking assessments (2000 - 2013; E).
Fulcher's research on rating scales has       directly impacted upon [text removed for publication] current scoring       procedures for all its English       language examinations.
His research on fluency assessment also impacted       upon the European       Common Framework of Reference for Languages, and the Association of       Language Testers in       Europe scale project.
Our research also affects quality control in examination boards.
Fulcher's research on retrofit       theory was internationally acknowledged in 2011 by the International       Language Testing       Association.
The 2009 publication Test Architecture, Test Retrofit       received a "Best Paper Award"       for its impact on the practice of examination boards.
The citation (A)       reads:     "The award committee found the paper by Fulcher and Davidson an excellent       conceptual       paper that emphasizes the centrality of test purpose in test design       decisions, and proposes       a systematic approach to evaluating test revisions and test retrofit.
The       paper is very well-written       and the authors guide the reader step by step through the processes of       careful       decision-making that language testers should undergo when changing tests       or test       purposes.
The use of the architecture metaphor is well-chosen and makes       the argument       compelling and accessible to a broad audience including practitioners.
Test retrofit has       been heatedly debated in public forums but has never seen such a       systematic treatment in       the scientific literature as in this paper.
The authors make a strong and       timely contribution       to the field of language testing in a period where tests are being used       for purposes they       were not originally intended for, or misused entirely, but the       consequences of test change       or change of test purpose for the validation process can hardly be found       in the literature.
Fulcher and Davidson provide the language testing field with the       appropriate terminology       and guidance for this important and timely topic."
In 2011 this led to an invitation for Fulcher to conduct staff       development training on retrofit theory       and practice in quality control processes for [text removed for       publication] staff.
In 2010 Fulcher       was also invited to provide training to test writers in the assessment       division of [text removed for       publication].
Our research is also important because of its social awareness and       justice components.
The       technical research into improved scoring and decision making is only       effective if it can be used by       teachers and examination boards to improve their practices.
Such impact       leads to fairer decision       making when using test scores.
Fulcher's Leverhulme-funded research into assessment teaching and       training has led to a range of       web-based tools (http://languagetesting.info)       that has impacted upon improved teaching of       language testing around the world.
For example, in 2011 the [text removed       for publication]       approached us to use these resources to train teachers in rural China (E).
A programme of       subtitling was undertaken (http://languagetesting.info/videos/subs.html)       and embedded within their       training scheme (F).
He was distinguished visiting lecture at       Temple University in Japan, delivering       public lectures on testing in society, and conducted a successful webinar       for teachers across the       Americas through San Diego State University in April 2012 (G).
Fulcher also edits the prestigious       journal Language Testing (Sage) and produces a quarterly podcast       to make content accessible to       the general public, as well as disseminating research in the popular       press.
We believe that impact       should extend beyond academia to engage a wider audience in important       social policy issues that       involve assessment practices.
