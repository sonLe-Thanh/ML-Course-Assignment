     Principal beneficiaries: Studies 1 and 2 have benefited the       Government, parents and schoolchildren while Study 3 has been of value to       society as a whole by encouraging policy-makers to be more careful about       the conclusions they draw from international comparative studies.
Dates of benefit: Studies 1 and 2: early January 2011       onwards; Study 3: from December 2011.
Reach and significance: As the evidence below shows, all three       studies have had both an instrumental impact2       (influencing policy) and a conceptual one (enhancing general understanding       and informing debate).
Each, in different ways, has ensured that teachers,       parents and the public should be better briefed about the measurement,       representation and substance of educational performance in future.
Parents       in England now receive more useful information on which to base school       choices as a result of Studies 1 and 2.
Children are therefore likely to       do better academically - because more families should make more       appropriate school choices.
Jerrim's study has made it less likely that       misleading evidence will be used to justify school reforms.
He has also       made the public more aware of the dangers of international comparisons.
Studies 1 and 2:     Allen and Burgess began discussing their proposed amendments to England's       performance tables at a DCSF meeting in February 2010 attended by the Head       of Research.
Vignoles also gave a presentation to the then shadow       education secretary, Michael Gove, in early 2010, highlighting the ADMIN       research on how best to measure school effectiveness and the problems with       CVA.
She and her colleagues had meetings with government officials and       Vignoles made presentations at the 2010 DCSF Research Conference and the       2011 Ministerial Seminar hosted by universities minister David Willetts.
The then IOE director, Geoff Whitty, briefed Graham Stuart MP, chair of       the House of Commons Education Select Committee, on the ADMIN research in       July 2011.
Mr Stuart then asked Allen and Burgess to present their       proposals to him in Westminster on November 10, 2011.
Allen has since had       several meetings with Tim Leunig, senior policy adviser to ministers at       the Department for Education (DfE) &#8212; see impact source S1.
Impact on tables: The research by Allen and Burgess       contributed to the DfE decision to remove the CVA measure from performance       tables from January 2011.
Lord Hill of Oareford, Parliamentary Under       Secretary of State for Education, confirmed this in the House of Lords on       January 19, 2011.
Asked by Lord Hunt of Kings Heath what academic evidence       the government had relied on in deciding to end the use of CVA, he       replied: "Research conducted by Allen and Burgess in 2010...found that CVA       is a less strong predictor of how well a child will do academically than       raw attainment measures" (S2).
The studies by Allen and Burgess,       and Dearden, Vignoles and Micklewright, also helped to convince the DfE       that it should change the tables again in January 2012.
This time it       decided to offer parents information about the GCSE performance of       children of similar ability to their own &#8212; in all schools in their local       area.
Both teams of researchers had recommended this change.
The DfE       agreed to divide children into three groups &#8212; low, middle and high       attainers &#8212; and indicate how they had progressed.
One advantage of this       approach is that it militates against schools focusing disproportionately       on pupils at the GCSE C/D threshold.
The tables are still not exactly as       the IOE researchers would wish &#8212; for example, each band includes a wider       ability range than they recommend &#8212; but it is an important step in the       right direction.
Furthermore, senior politicians are continuing to seek       their advice.
Allen was invited to take part in a closed roundtable       discussion on school accountability with the Deputy Prime Minister, Nick       Clegg, on April 16, 2013.
She and Dearden also advised the Education       Select Committee on performance tables on the same day.
On July 2, 2013,       Allen again briefed Graham Stuart as he prepared to discuss performance       tables with Michael Gove.
She pointed to problems with the calculation of       progress measures for the KS4 tables, the potentially distorting effects       of the new 'best 8' GCSEs measure, and the case for and against threshold       measures such as 5 A-C grades at GCSE.
Allen was also asked to provide the       DfE with technical advice (in June 2013) on the new value added measures       to be used in the 2013 performance tables.
This advice included       recommendations for the most appropriate statistical model for predicting       pupil GCSE performance.
Wider influence: Audiences beyond Westminster and academia       have been reached via the very accessible blogs that Allen (www.rebeccaallen.co.uk)       has written and by the media coverage that the ADMIN node work has       attracted (S3).
Study 3:     Jerrim issued a press release about his study that triggered substantial       media coverage in December 2011.
Stephen Twigg, the then Shadow Education       Secretary, told the BBC: "This report demonstrates that the claims that       pupils in England have been sliding down the international performance       tables are unfounded" (S4).
Headteachers' leader Brian Lightman       said that the study had shown that international comparisons should come       with health warnings.
The DfE, however, continued to insist that PISA       highlighted the scale of the decline in pupil performance.
The following       September the Chief Inspector, Sir Michael Wilshaw, also reasserted that       England had fallen from 7th to 28th in the PISA mathematics table between       2000 and 2009.
Dilnot investigates: The Wilshaw statement prompted former       schools minister David Miliband to complain to Sir Andrew Dilnot, chair of       the UK Statistics Authority.
Sir Andrew investigated and sent Mr Miliband       an open letter supporting his complaint in October, 2012 (S5).
He       said that the OECD had confirmed that gaps in some years' PISA data made       accurate comparisons difficult.
Sir Andrew said he had also noted Dr       Jerrim's study which reported that 1) there were problems with identifying       change over time using PISA data for England 2) conclusions should not be       based on this resource alone, and 3) other evidence, including TIMSS,       contradicts PISA findings (S6).
He (Dilnot) was concerned that       PISA rankings had been used in a DfE press release in December 2010       without the necessary "detailed advice or caveats".
He said he would       discuss this issue with the Department and copy his letter to the Chief       Inspector, the National Statistician, and to the Heads of Profession for       Statistics at the DfE and Ofsted.
Sir Andrew later had a high-level       meeting at the DFE and there is evidence that his advice has been heeded.
In December 2010, Michael Gove, the Education Secretary, told TES       readers that "PISA 2009 shows that thoroughgoing reform of our schools is       urgently necessary" (S7).
But by May 2013, when he appeared before       the Education Select Committee, Mr Gove had modified his claims.
Under       questioning, he acknowledged that cross-country comparisons using PISA       data were "complex" (S8).
It is therefore evident that Jerrim's       study, which was also referred to in a Guardian leader in       September 2012 (S9), has helped to shape this important debate.
